---
questionAnswers: []
id: '1025529'
title: Building Trustworthy and Reliable LLM Applications
description: "We are entering the next wave of LLM understanding, so we want to make
  Natural Language Processing applications more reliable, robust, and trustworthy.
  This talk introduces the best practices and techniques for securing LLMs through
  guardrails that monitor and filter inputs and outputs. \r\n\r\nWeâ€™ll examine how
  to effectively prevent malicious intent in inputs and protect against the exposure
  of sensitive data in outputs, using practical examples with Hugging Face and OpenAI
  models.\r\n\r\nThrough live demonstrations, attendees will learn how tools like
  LangChain4J can work together to detect and mitigate risks such as prompt injection
  attacks, unauthorized data access, poisoning RAG, and sanitization. \r\n\r\nThe
  session will conclude with a discussion on the evolving landscape of LLM security,
  the importance of vigilant permissions, and continuous monitoring to safeguard user
  and organizational data. This talk is ideal for developers, security practitioners,
  and anyone responsible for deploying LLMs into real-world applications.\r\n"
startsAt:
endsAt:
isServiceSession: false
isPlenumSession: false
speakers:
- id: dedbce11-34e0-466e-a5cb-ea585688d106
  name: Alex Soto
- id: b4ec38ee-2a62-40f0-85ab-2b4811d2f380
  name: Markus Eisele
categories:
- id: 107979
  name: Track
  categoryItems:
  - id: 389041
    name: Security
  sort: 0
roomId:
room:
liveUrl:
recordingUrl:
status: Accepted
isInformed: true
isConfirmed: true
track: Security
slug: building-trustworthy-and-reliable-llm-applications

---
