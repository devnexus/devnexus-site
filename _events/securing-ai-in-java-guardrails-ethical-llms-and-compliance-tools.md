---
questionAnswers: []
id: '1031652'
title: 'Securing AI in Java: Guardrails, Ethical LLMs, and Compliance Tools'
description: "As large language models (LLMs) are integrated into enterprise systems,
  Java teams face emerging risks, including prompt injection, bias, and data governance
  failures, which can quickly erode user trust and stall production rollouts. Focusing
  on real threats identified in todayâ€™s OWASP LLM risk landscape, this session delivers
  hands-on approaches for Java developers to harden their AI-powered applications.\r\n\r\nThe
  talk details defence-in-depth strategies: automated bias screening, prompt sanitization
  techniques, and compliant logging workflows, all implemented using LangChain4j and
  Jakarta EE for scalable, modular LLM orchestration. \r\n\r\nYou will walk away with
  concrete, ready-to-apply patterns and code-level practices to build secure, ethical,
  and regulation-ready LLM apps in modern Java environments."
startsAt:
endsAt:
isServiceSession: false
isPlenumSession: false
speakers:
- id: 79e95ec4-23ec-48ec-9046-98d3e1776283
  name: Bazlur Rahman
- id: 4e0f1b70-c9ff-4351-b21e-eee43fdd44df
  name: Shaaf Syed
categories:
- id: 107979
  name: Track
  categoryItems:
  - id: 389041
    name: Security
  sort: 0
roomId:
room:
liveUrl:
recordingUrl:
status: Accepted
isInformed: true
isConfirmed: true
track: Security
slug: securing-ai-in-java-guardrails-ethical-llms-and-compliance-tools

---
